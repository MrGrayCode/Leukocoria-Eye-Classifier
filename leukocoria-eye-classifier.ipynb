{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "abf9bdfc84298213a7d7044c4a0c007b35e971f9"
   },
   "source": [
    "# Reading Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c0674b1446521fc84fb095996037e49578467cc1"
   },
   "outputs": [],
   "source": [
    "#get all the input data paths and randomly shuffle them\n",
    "data_paths = sorted(list(paths.list_images(\"../input/hestia-epoch/train data/Train data\")))\n",
    "\n",
    "random.seed(1203)\n",
    "random.shuffle(data_paths)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "encode = {\"leukocoria\":1,\"non-leukocoria\":0}\n",
    "#add img array to data\n",
    "for path in data_paths:\n",
    "    #read image from image path\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    img = cv2.resize(img,(28,28))\n",
    "    img = img_to_array(img)\n",
    "\n",
    "    #add images to data list\n",
    "    data.append(img)\n",
    "    \n",
    "    #add encoded lable to label list\n",
    "    label = path.split(os.path.sep)[-2]\n",
    "    labels.append(encode[label])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bee09b32aca500e7baaae244abf3637e66bbdbb3"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8361c666990ffe7013cb0db5fe73c313df3607d5"
   },
   "outputs": [],
   "source": [
    "#scaling data\n",
    "data = np.array(data, dtype = float) / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "#train-test split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size = 0, random_state = 1203)\n",
    "\n",
    "#one hot encoding of labels\n",
    "trainY = to_categorical(trainY, num_classes = 2)\n",
    "testY = to_categorical(testY, num_classes = 2)\n",
    "\n",
    "#data augmentation for image generator\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9471d6b5ced84068c2add0cdd62469c384ec79e1"
   },
   "source": [
    "# The Model -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d6c945e6607f14a0118cad1fe651884c5b65efaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#some parameters for the model\n",
    "height = 28\n",
    "width = 28\n",
    "depth = 3\n",
    "classes = 2\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (height, width, depth)\n",
    "model.add(Conv2D(20,(5,5), padding = \"same\", input_shape = input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
    "model.add(Conv2D(50, (5,5), padding = \"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#softmax\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27462d7f490357beb15e960a1fdc76fbcc62c63e"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "3247d79d7a620cb5670e7ab3da12450030f70f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Compiling the Model]\n",
      "[Training]\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.5537 - acc: 0.7733\n",
      "Epoch 2/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.4748 - acc: 0.7811\n",
      "Epoch 3/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.4104 - acc: 0.8068\n",
      "Epoch 4/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.3752 - acc: 0.8509\n",
      "Epoch 5/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.3570 - acc: 0.8554\n",
      "Epoch 6/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.3385 - acc: 0.8677\n",
      "Epoch 7/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2933 - acc: 0.8721\n",
      "Epoch 8/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2779 - acc: 0.8844\n",
      "Epoch 9/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2921 - acc: 0.8889\n",
      "Epoch 10/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2854 - acc: 0.8811\n",
      "Epoch 11/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2641 - acc: 0.8933\n",
      "Epoch 12/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2254 - acc: 0.9095\n",
      "Epoch 13/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2440 - acc: 0.8989\n",
      "Epoch 14/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2168 - acc: 0.9123\n",
      "Epoch 15/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.2279 - acc: 0.9040\n",
      "Epoch 16/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2552 - acc: 0.9045\n",
      "Epoch 17/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2260 - acc: 0.9129\n",
      "Epoch 18/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1967 - acc: 0.9285\n",
      "Epoch 19/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2135 - acc: 0.9129\n",
      "Epoch 20/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1819 - acc: 0.9246\n",
      "Epoch 21/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1754 - acc: 0.9336\n",
      "Epoch 22/60\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.1461 - acc: 0.9520\n",
      "Epoch 23/60\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.1621 - acc: 0.9308\n",
      "Epoch 24/60\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 0.1770 - acc: 0.9246\n",
      "Epoch 25/60\n",
      "28/28 [==============================] - 2s 85ms/step - loss: 0.1706 - acc: 0.9397\n",
      "Epoch 26/60\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 0.1761 - acc: 0.9285\n",
      "Epoch 27/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1543 - acc: 0.9414\n",
      "Epoch 28/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1549 - acc: 0.9386\n",
      "Epoch 29/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1640 - acc: 0.9408\n",
      "Epoch 30/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1462 - acc: 0.9470\n",
      "Epoch 31/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1634 - acc: 0.9425\n",
      "Epoch 32/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.2048 - acc: 0.9185\n",
      "Epoch 33/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1488 - acc: 0.9414\n",
      "Epoch 34/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1514 - acc: 0.9375\n",
      "Epoch 35/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1540 - acc: 0.9442\n",
      "Epoch 36/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1340 - acc: 0.9531\n",
      "Epoch 37/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1364 - acc: 0.9520\n",
      "Epoch 38/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1355 - acc: 0.9570\n",
      "Epoch 39/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1344 - acc: 0.9447\n",
      "Epoch 40/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1031 - acc: 0.9682\n",
      "Epoch 41/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1202 - acc: 0.9598\n",
      "Epoch 42/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1163 - acc: 0.9458\n",
      "Epoch 43/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1199 - acc: 0.9603\n",
      "Epoch 44/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1242 - acc: 0.9581\n",
      "Epoch 45/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0958 - acc: 0.9726\n",
      "Epoch 46/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0895 - acc: 0.9587\n",
      "Epoch 47/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0878 - acc: 0.9643\n",
      "Epoch 48/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1128 - acc: 0.9531\n",
      "Epoch 49/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1734 - acc: 0.9347\n",
      "Epoch 50/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1319 - acc: 0.9514\n",
      "Epoch 51/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0985 - acc: 0.9587\n",
      "Epoch 52/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0985 - acc: 0.9654\n",
      "Epoch 53/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.1029 - acc: 0.9603\n",
      "Epoch 54/60\n",
      "28/28 [==============================] - 2s 68ms/step - loss: 0.0937 - acc: 0.9643\n",
      "Epoch 55/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.1076 - acc: 0.9598\n",
      "Epoch 56/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0869 - acc: 0.9665\n",
      "Epoch 57/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.1087 - acc: 0.9637\n",
      "Epoch 58/60\n",
      "28/28 [==============================] - 2s 67ms/step - loss: 0.0951 - acc: 0.9637\n",
      "Epoch 59/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0768 - acc: 0.9665\n",
      "Epoch 60/60\n",
      "28/28 [==============================] - 2s 66ms/step - loss: 0.0824 - acc: 0.9659\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "EPOCHS = 60\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "print(\"[Compiling the Model]\")\n",
    "opt = Adam(lr = INIT_LR, decay=INIT_LR/EPOCHS)\n",
    "#opt = RMSprop(lr = INIT_LR, decay=INIT_LR/EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics = [\"accuracy\"])\n",
    "\n",
    "print(\"[Training]\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size = BS), steps_per_epoch = ceil(len(trainX) / BS), epochs = EPOCHS, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5899e6329d55586dba0e1fe0f65e2e1638c53c43"
   },
   "source": [
    "# Evaluating The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "4994d685a424c82cea0198115b35eb1b9ef0e990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 0]\n",
      "['1', 0]\n",
      "['10', 0]\n",
      "['100', 0]\n",
      "['101', 1]\n",
      "['102', 0]\n",
      "['103', 0]\n",
      "['104', 0]\n",
      "['105', 0]\n",
      "['106', 0]\n",
      "['107', 0]\n",
      "['108', 0]\n",
      "['109', 0]\n",
      "['11', 0]\n",
      "['110', 0]\n",
      "['111', 0]\n",
      "['112', 0]\n",
      "['113', 0]\n",
      "['114', 0]\n",
      "['115', 1]\n",
      "['116', 0]\n",
      "['117', 1]\n",
      "['118', 0]\n",
      "['119', 0]\n",
      "['12', 0]\n",
      "['120', 0]\n",
      "['121', 1]\n",
      "['122', 0]\n",
      "['123', 0]\n",
      "['124', 0]\n",
      "['125', 1]\n",
      "['126', 0]\n",
      "['127', 0]\n",
      "['128', 0]\n",
      "['129', 0]\n",
      "['13', 0]\n",
      "['130', 0]\n",
      "['131', 0]\n",
      "['132', 1]\n",
      "['133', 0]\n",
      "['134', 0]\n",
      "['135', 0]\n",
      "['136', 0]\n",
      "['137', 0]\n",
      "['138', 0]\n",
      "['139', 0]\n",
      "['14', 1]\n",
      "['140', 1]\n",
      "['141', 0]\n",
      "['142', 0]\n",
      "['143', 0]\n",
      "['144', 0]\n",
      "['145', 1]\n",
      "['146', 0]\n",
      "['147', 1]\n",
      "['148', 0]\n",
      "['149', 0]\n",
      "['15', 0]\n",
      "['150', 0]\n",
      "['151', 0]\n",
      "['152', 0]\n",
      "['153', 1]\n",
      "['154', 1]\n",
      "['155', 0]\n",
      "['156', 0]\n",
      "['157', 0]\n",
      "['158', 1]\n",
      "['159', 0]\n",
      "['16', 0]\n",
      "['160', 0]\n",
      "['161', 0]\n",
      "['162', 0]\n",
      "['163', 0]\n",
      "['164', 0]\n",
      "['165', 1]\n",
      "['166', 1]\n",
      "['167', 0]\n",
      "['168', 0]\n",
      "['169', 0]\n",
      "['17', 0]\n",
      "['170', 0]\n",
      "['171', 0]\n",
      "['172', 0]\n",
      "['173', 0]\n",
      "['174', 0]\n",
      "['175', 1]\n",
      "['176', 0]\n",
      "['177', 0]\n",
      "['178', 0]\n",
      "['179', 0]\n",
      "['18', 1]\n",
      "['180', 0]\n",
      "['181', 0]\n",
      "['182', 0]\n",
      "['183', 0]\n",
      "['184', 1]\n",
      "['185', 0]\n",
      "['186', 0]\n",
      "['187', 0]\n",
      "['188', 1]\n",
      "['189', 0]\n",
      "['19', 0]\n",
      "['190', 0]\n",
      "['191', 0]\n",
      "['192', 0]\n",
      "['193', 0]\n",
      "['194', 0]\n",
      "['195', 0]\n",
      "['196', 0]\n",
      "['197', 0]\n",
      "['198', 1]\n",
      "['199', 0]\n",
      "['2', 1]\n",
      "['20', 0]\n",
      "['21', 1]\n",
      "['22', 1]\n",
      "['23', 0]\n",
      "['24', 0]\n",
      "['25', 0]\n",
      "['26', 1]\n",
      "['27', 0]\n",
      "['28', 0]\n",
      "['29', 1]\n",
      "['3', 0]\n",
      "['30', 0]\n",
      "['31', 0]\n",
      "['32', 0]\n",
      "['33', 1]\n",
      "['34', 1]\n",
      "['35', 0]\n",
      "['36', 0]\n",
      "['37', 0]\n",
      "['38', 0]\n",
      "['39', 0]\n",
      "['4', 0]\n",
      "['40', 0]\n",
      "['41', 0]\n",
      "['42', 0]\n",
      "['43', 1]\n",
      "['44', 0]\n",
      "['45', 1]\n",
      "['46', 0]\n",
      "['47', 1]\n",
      "['48', 0]\n",
      "['49', 0]\n",
      "['5', 0]\n",
      "['50', 1]\n",
      "['51', 0]\n",
      "['52', 0]\n",
      "['53', 0]\n",
      "['54', 0]\n",
      "['55', 0]\n",
      "['56', 0]\n",
      "['57', 0]\n",
      "['58', 0]\n",
      "['59', 0]\n",
      "['6', 0]\n",
      "['60', 0]\n",
      "['61', 0]\n",
      "['62', 0]\n",
      "['63', 0]\n",
      "['64', 0]\n",
      "['65', 1]\n",
      "['66', 1]\n",
      "['67', 1]\n",
      "['68', 0]\n",
      "['69', 1]\n",
      "['7', 0]\n",
      "['70', 0]\n",
      "['71', 0]\n",
      "['72', 0]\n",
      "['73', 0]\n",
      "['74', 1]\n",
      "['75', 0]\n",
      "['76', 0]\n",
      "['77', 0]\n",
      "['78', 0]\n",
      "['79', 0]\n",
      "['8', 0]\n",
      "['80', 0]\n",
      "['81', 0]\n",
      "['82', 0]\n",
      "['83', 0]\n",
      "['84', 0]\n",
      "['85', 0]\n",
      "['86', 0]\n",
      "['87', 1]\n",
      "['88', 1]\n",
      "['89', 1]\n",
      "['9', 0]\n",
      "['90', 0]\n",
      "['91', 0]\n",
      "['92', 0]\n",
      "['93', 1]\n",
      "['94', 0]\n",
      "['95', 0]\n",
      "['96', 0]\n",
      "['97', 0]\n",
      "['98', 0]\n",
      "['99', 0]\n"
     ]
    }
   ],
   "source": [
    "data_paths = sorted(list(paths.list_images(\"../input/hestia-epoch/evaluation data/Evaluation data\")))\n",
    "a = 0.3\n",
    "b = 0.7\n",
    "\n",
    "#variable for writing to the csv file\n",
    "with open(\"submission2.csv\",'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Id\",\"Category\"])\n",
    "    for path in data_paths:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "        img = cv2.resize(img,(28,28))\n",
    "        img = img.astype(\"float\")/255.0\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "        (neg, pos) = model.predict(img)[0]\n",
    "        neg = (neg + a)/2\n",
    "        pos = (pos + b)/2\n",
    "        label = 0 if neg > pos else 1\n",
    "        i = path.split(os.path.sep)[-1]\n",
    "        i = i[:-4]\n",
    "        \n",
    "        row = [i, label]\n",
    "        print(row)\n",
    "        #print(i,neg, pos)\n",
    "        writer.writerow(row)\n",
    "        \n",
    "f.close()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
